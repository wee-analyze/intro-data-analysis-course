{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert panda dataframes into numpy arrays containing only the values of the pandas dataframe using .values. (have to be careful with your datatypes though). You might want to do this to take the mean of all the data points instead of just one column which is what would happen in pandas.\n",
    "\n",
    "dataframes can have indexes. use .loc to specify those indexes and .iloc to specify positions when there is no index.\n",
    "\n",
    "inplace = True means that the original data will be modifies. False means that a new object will be created IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized Operations and index arrays for panda series. Notice that the first print which \n",
    "# is the first 5 rows answered like indexes. index 0 answer is 2. index 1 answer is 4. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "a = pd.Series([1, 2, 3, 4])\n",
    "b = pd.Series([1, 2, 1, 2])\n",
    "  \n",
    "print a + b\n",
    "print a * 2\n",
    "print a >= 3\n",
    "print a[a >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding DataFrames with overlapping column names\n",
    "# Notice that if you add a number to NaN you get Nan!\n",
    "\n",
    "if True:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "\n",
    "# Adding DataFrames with overlapping row indexes\n",
    "if True:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print df1 + df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can shift indexes and columns with .shift(). Look at documentation, which just happens to be poorly written as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative entries and exits for one station for a few hours.\n",
    "# Calculate difference. This is not Entries - exits. This is \n",
    "# finding the difference between numbers in it's respective column\n",
    "\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n",
    "    \n",
    "print get_hourly_entries_and_exits(entries_and_exits)\n",
    "\n",
    "# Another answer is .diff()\n",
    "# return entries_and_exits.diff() with this you can do differences in\n",
    "# columns or indexes. For columns it's .diff(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using .diff()\n",
    "# default will be differences in indexes. Differences in column\n",
    "# can be done with .diff(axis = 1)\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n",
    "    \n",
    "print get_hourly_entries_and_exits(entries_and_exits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"xxx.csv\")\n",
    "\n",
    ".head() #prints first 5 lines\n",
    "\n",
    ".describe() # shows some statistics of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for large files you can peak without loading all. This will load the first 6 rows\n",
    "pd.read_csv(\"xxx.csv\", nrow=6).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Peak in the middle of the large file\n",
    "pd.read_csv(\"xxx.csv\", nrow=6, skiprows=10, header=None).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra features not found in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main difference is that panda series has has something called an index\n",
    "# and columns\n",
    "\n",
    "#numpy would look like this\n",
    "# countries = np.array([\"albania\", \"Algeria\", \"Andorra\"])\n",
    "# life_expectancy = np.array([74.7, 75., 83.4])\n",
    "\n",
    "# pandas looks like\n",
    "life_expectancy = pd.Series([74.7, 75., 83.4],\n",
    "                   index = [\"albania\",\n",
    "                            \"Algeria\", \n",
    "                            \"Andorra\"])\n",
    "\n",
    "print life_expectancy\n",
    "\n",
    "# NumPy arrays are like souped-up Python lists\n",
    "# Pandas series is like a cross between a list and a dictionary\n",
    "\n",
    "# you can use .loc to find using the index without needing to know the position in t\n",
    "# the list\n",
    "print life_expectancy.loc[\"Algeria\"]\n",
    "\n",
    "# When you don't have an index consider the following when accessing positions.\n",
    "# you should use .iloc\n",
    "print life_expectancy.iloc[0] # if there was not index givin in the series\n",
    "print life_expectancy[0] # this has the same result but is confusing because it's NOT an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding index with that has max value\n",
    "# use idxmax()\n",
    "employment_values = [\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695\n",
    "]\n",
    "\n",
    "countries = [\n",
    "    'Afghanistan', 'Albania', 'Algeria', 'Angola'\n",
    "]\n",
    "\n",
    "employment = pd.Series(employment_values, index=countries)\n",
    "\n",
    "def max_employment(employment):\n",
    "    max_country = None\n",
    "    max_value = None\n",
    "    \n",
    "    max_country = employment.idxmax()\n",
    "    max_value = employment.loc[max_country]\n",
    "    \n",
    "    return (max_country, max_value)\n",
    "\n",
    "max_employment(employment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe function lists a lot of statiscital info\n",
    "a = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "a.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop NaN or fill missing indexes with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Indexes that don't overlap. you get NaN\n",
    "s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "s2 = pd.Series([10, 20, 30, 40], index=['e', 'f', 'a', 'h'])\n",
    "sum_result = s1 + s2\n",
    "print sum_result\n",
    "\n",
    "# to get rid of NaN us .dropna()\n",
    "print sum_result.dropna()\n",
    "\n",
    "# to fill in NaN with 0 you can use .fillna(0)\n",
    "print sum_result.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to add series with missing indexes so the missing\n",
    "# get added as 0 instead of NaN. Just had to google this question to \n",
    "# find this answer\n",
    "import pandas as pd\n",
    "\n",
    "s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "s2 = pd.Series([10, 20, 30, 40], index=['c', 'd', 'e', 'f'])\n",
    "\n",
    "# Try to write code that will add the 2 previous series together,\n",
    "# but treating missing values from either series as 0. The result\n",
    "# when printed out should be similar to the following line:\n",
    "# print pd.Series([1, 2, 13, 24, 30, 40], index=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "\n",
    "combine = s1 + s2\n",
    "s1.add(s2, fill_value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using .apply() to use functions instead of loops (for whole series IT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".apply can also be used on dataframes but when you use this you are looking at calculate on the whole series (column or row) IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use APPLY instead of loops to apply a function to a whole panda series. \n",
    "# notice the function is in the parenthesis of apply\n",
    "\n",
    "names = pd.Series([\n",
    "    'Andre Agassi',\n",
    "    'Barry Bonds',\n",
    "    'Christopher Columbus'])\n",
    "\n",
    "\n",
    "# Make function to return a new series where each name\n",
    "# in the input series has been transformed from the format\n",
    "# \"Firstname Lastname\" to \"Lastname, FirstName\".\n",
    "# Try to use the Pandas apply() function rather than a loop.\n",
    "\n",
    "# easier to make a def for one name first to test that it works\n",
    "def reverse_name(name):\n",
    "    new_name = name.split(\" \")\n",
    "    first_name = new_name[0]\n",
    "    last_name = new_name[1]\n",
    "    return first_name + \", \" + last_name\n",
    "\n",
    "print reverse_name(names.iloc[0]) #.iloc clearly shows POSITION for series missing an index\n",
    "    \n",
    "# now that you know it works you can use APPLY() to use for whole series\n",
    "def reverse_names(players):\n",
    "    return names.apply(reverse_name)\n",
    "    \n",
    "reverse_names(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .apply(function) on dataframes. Use this to treat whole columns as rows as data instead of each element  in dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note when using standard deviation like in example below: In order to get the proper computations, we should actually be setting the value of the \"ddof\" parameter to 0 in the .std() function.\n",
    "\n",
    "Note that the type of standard deviation calculated by default is different between numpy's .std() and pandas' .std() functions. By default, numpy calculates a population standard deviation, with \"ddof = 0\". On the other hand, pandas calculates a sample standard deviation, with \"ddof = 1\". If we know all of the scores, then we have a population - so to standardize using pandas, we need to set \"ddof = 0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example\n",
    "import pandas as pd\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "# see steps for solution below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make function to standerdize a series (in this case it will be the exam1 or exame2)\n",
    "\n",
    "def standardize_column(data):\n",
    "    return (data - data.mean()) / data.std(ddof=0)\n",
    "    \n",
    "print standardize_column(grades_df[\"exam1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert that function into another function with .apply(first_function) so that you can apply it\n",
    "# to the columns or rows in the dataframe\n",
    "def standardize(df):\n",
    "    return df.apply(standardize_column)\n",
    "\n",
    "print standardize(grades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### you can also use apply to apply functions on series in a dataframe and return just a single value instead of the whole new series again. See example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example to use .apply for using a function to be applies to a series in dataframe (can be row or column) and\n",
    "# return just a single calculation value.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To get the idea. Change False to True for this block of code to see what it does\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "if True:   \n",
    "    print df.apply(np.mean)\n",
    "    print df.apply(np.max) - df.apply(np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "def second_largest(df):\n",
    "    '''\n",
    "    Fill in this function to return the second-largest value of each \n",
    "    column of the input DataFrame.\n",
    "    '''\n",
    "    return None\n",
    "\n",
    "# see solution below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. Make function that works on one column\n",
    "# sort_value() works on a panda series.\n",
    "\n",
    "def sort_order_2nd_largest(column):\n",
    "    sorted_column = column.sort_values(ascending = False)\n",
    "    return sorted_column.iloc[1]\n",
    "\n",
    "sort_order_2nd_largest(df[\"a\"]) # test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2. Use apply(function) so sort_value() can be used on all series in the dataframe.\n",
    "def second_largest(df):\n",
    "    return df.apply(sort_order_2nd_largest)\n",
    "\n",
    "second_largest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using applymap to use functions to be used on all elements in a dataframe. (not treating as a series but on each element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "import pandas as pd\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame applymap()\n",
    "if False:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "    \n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print df.applymap(add_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 2\n",
    "# convert scores to letter grades\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "# step 1. Make function that converts one element\n",
    "def convert_score(grade):\n",
    "    if grade >= 90:\n",
    "        return \"A\"\n",
    "    elif grade >= 80:\n",
    "        return \"B\"\n",
    "    elif grade >= 70:\n",
    "        return \"C\"\n",
    "    elif grade >= 60:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"F\"\n",
    "    \n",
    "# test it\n",
    "convert_score(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")   \n",
    "    \n",
    "# then use applymap() to apply one function to whole datafram\n",
    "def convert_grades(grades):\n",
    "    return grades.applymap(convert_score)\n",
    "    \n",
    "convert_grades(grades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding dataframe to series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy and paste these individually to see them visually as outputs (see cell below). It's easier to see what's going on.\n",
    "# cool trick is to add the series with .add(series, axis = \"index\"). It treats the series as index instead of column (default IT)\n",
    "# see example of changing axis somewhere in cell below\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding a Series to a one-row DataFrame \n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "\n",
    "# Adding a Series to a one-column DataFrame\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "\n",
    "    \n",
    "# Adding when DataFrame column names match Series index\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding when DataFrame column names don't match Series index\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "df = pd.DataFrame({\n",
    "    'a': [10, 20, 30, 40],\n",
    "    'b': [50, 60, 70, 80],\n",
    "    'c': [90, 100, 110, 120],\n",
    "    'd': [130, 140, 150, 160]\n",
    "})\n",
    "\n",
    "print df\n",
    "print '' # Create a blank line between outputs\n",
    "print df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({\n",
    "    0: [10, 20, 30, 40],\n",
    "    1: [50, 60, 70, 80],\n",
    "    2: [90, 100, 110, 120],\n",
    "    3: [130, 140, 150, 160]\n",
    "})\n",
    "\n",
    "print df\n",
    "print '' # Create a blank line between outputs\n",
    "print df.add(s, axis='index')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding dataframe to series problem with also changing axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standerdize each ROW using vectorized operations\n",
    "# equation if you did it by column would be (grades_df - grades_df.mean()) / grades_df.std(ddof=0). so you need \n",
    "# to change the axis\n",
    "\n",
    "# look at the dataframe to see things clearly\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean of each ROW\n",
    "# equation if you did it by column would be (grades_df - grades_df.mean()) / grades_df.std(ddof=0). so you need \n",
    "# to change the axis\n",
    "\n",
    "grades_df.mean(axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can't subtract the mean by ROW from the grades_df because your just gonna get a \n",
    "# bunch of NaNs because these means by ROW don't match up with the the columns of the df. Try it and see.\n",
    "# So you need to subtract by the ROWS of the grades_df. \n",
    "\n",
    "\n",
    "# equation if you did it by column would be (grades_df - grades_df.mean()) / grades_df.std(ddof=0). so you need \n",
    "# to change the axis\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "grades_df - grades_df.mean(axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the axis of the df. Since you did mean by row you want to subract that mean by ROW \n",
    "# of the dataframe as well which is it's index. Use sub() to you can change the axis of the df from \n",
    "# which your subracting. Your matching your averages taken by row to the index of the dataframe\n",
    "\n",
    "# equation if you did it by column would be (grades_df - grades_df.mean()) / grades_df.std(ddof=0). so you need \n",
    "# to change the axis\n",
    "\n",
    "mean_diffs = grades_df.sub(grades_df.mean(axis = \"columns\"), axis = \"index\")\n",
    "mean_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you need to divide the standard deviation. Again, since your taking the standard deviation by row you want to \n",
    "# match those values with the dataframes indexes. So, you need to change the axis of the dataframe to \"index\"\n",
    "\n",
    "# equation if you did it by column would be (grades_df - grades_df.mean()) / grades_df.std(ddof=0). so you need \n",
    "# to change the axis\n",
    "\n",
    "mean_diffs.div(grades_df.std(ddof=0, axis = \"columns\"), axis = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you used a function here is one way it could look. It was somcebody elses and is very clean.\n",
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    \n",
    "    for index, row in df.iterrows(): \n",
    "        mean = df.loc[index].mean()\n",
    "        std = df.loc[index].std(ddof = 0)\n",
    "        df.loc[index] = (df.loc[index] - mean)/std\n",
    "    return df\n",
    "    \n",
    "    \n",
    "print standardize_rows(grades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping data using groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see the mapping of the groups by using the .groups attribute when\n",
    "using groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Examine DataFrame\n",
    "if False:\n",
    "    print example_df\n",
    "    \n",
    "# Examine groups\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Group by multiple columns\n",
    "if False:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Get sum of each group\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data.sum()\n",
    "    \n",
    "# Limit columns in result\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print grouped_data.sum()['value']\n",
    "    \n",
    "    print '\\n' # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print grouped_data['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex example of how to use groupby() in pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "engagement_df = pd.DataFrame({\n",
    "    \"account_key\": [\"1\", \"3\", \"3\"],\n",
    "    \"utc_date\": [\"2015-03-04\", \"2015-10-02\", \"2015-01-21\"],\n",
    "    \"total_minutes_visited\": [331.3, 65.7, 902.4],\n",
    "    \"minutes_sleeping\": [12.2, 20.0, 34.3]\n",
    "})\n",
    "\n",
    "\n",
    "# calculated mean of all students together\n",
    "engagement_df.groupby(\"account_key\").sum()[\"total_minutes_visited\"].mean()\n",
    "# you can see the mapping of the groups by using the .groups attribute when\n",
    "# using groupby()\n",
    "# breakdown of what this means step by step below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an object without you writing it equal to an\n",
    "# object. To see the contents of object use .groups\n",
    "# engagement_df.groupby(\"account_key\").sum()[\"total_minutes_visited\"].mean()\n",
    "print engagement_df.groupby(\"account_key\")\n",
    "print engagement_df.groupby(\"account_key\").groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds each column in each group. notice it's in a dataframe and that the \n",
    "# date column is not included because it has no value. \n",
    "# engagement_df.groupby(\"account_key\").sum()[\"total_minutes_visited\"].mean()\n",
    "engagement_df.groupby(\"account_key\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifies one column your interested in and changes it into a pandas series \n",
    "# instead of a dataframe\n",
    "# engagement_df.groupby(\"account_key\").sum()[\"total_minutes_visited\"].mean()\n",
    "engagement_df.groupby(\"account_key\").sum()[\"total_minutes_visited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the mean of all of this\n",
    "# engagement_df.groupby(\"account_key\").sum()[\"total_minutes_visited\"].mean()\n",
    "engagement_df.groupby(\"account_key\").sum()[\"total_minutes_visited\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot this\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%pylab inline\n",
    "import seaborn as sns # makes nicer plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging several dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar to join for SQL.\n",
    "Watch this video\n",
    "https://www.youtube.com/watch?time_continue=82&v=vB_Et1hz_2M\n",
    "you can also merge columns that have different names if they happened to be spelled differently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns # makes nicer plots\n",
    "\n",
    "# you need this line to show the plot when using python notebook!\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "data_set = pd.Series([1, 100, 500, 1076])\n",
    "               \n",
    "# make histograms\n",
    "# data.hist()\n",
    "data_set.hist() # with gridlines\n",
    "data_set.plot.hist() # without gridlines\n",
    "\n",
    "# plots\n",
    "# data.plot()\n",
    "# s1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "%pylab inline\n",
    "data_set.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can have different types of data (strings, int, etc) in each column and perform calculations even though they are different types.\n",
    "\n",
    "You can convert panda dataframes into numpy arrays containing only the values of the pandas dataframe using .values. (have to be careful with your datatypes though). You might want to do this to take the mean of all the data points instead of just one column which is what would happen in pandas.\n",
    "\n",
    "Look at the code above for an example of turning pandas dataframe into nyumpy arrays of values to perform some functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation along axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Operations along an axis. Most arguments in numpy take (axis = 0) or (axis = 1) argument which calculates functions for each column or each row.\n",
    "\n",
    "(axis = 0) takes each column\n",
    "(axis = 1) takes each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pandas axis\n",
    "if True:\n",
    "    df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df\n",
    "    print df.sum()\n",
    "    print df.sum(axis=1)\n",
    "    print df.values.sum() # se below for description of .values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting pandas dataframes to numpy arrays with values to use functions on whole set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see above and below for examples. Have to be careful with datatypes. When you use .values your changing the pandas dataframe to a numpy array IT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "df.values.sum()\n",
    "df.values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrames\n",
    "if True:\n",
    "    # You can create a DataFrame out of a dictionary mapping column names to values\n",
    "    df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df_1\n",
    "\n",
    "    # You can also use a list of lists or a 2D NumPy array\n",
    "    df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "    print df_2\n",
    "    print df_2.values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691]],\n",
    "    index= ['05-01-11', '05-02-11', '05-03-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "      \n",
    "# Accessing elements\n",
    "if True:\n",
    "    print ridership_df.iloc[0] # not using index\n",
    "    print ridership_df.loc['05-02-11'] # using index\n",
    "    print ridership_df['R003'] # selecting column\n",
    "    print ridership_df.iloc[1, 3] # selecting specific row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691]],\n",
    "    index= ['05-01-11', '05-02-11', '05-03-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "# Accessing multiple rows\n",
    "if True:\n",
    "    print ridership_df.iloc[1:3] # doesn't include the row 3\n",
    "    \n",
    "# Accessing multiple columns\n",
    "if True:\n",
    "    print ridership_df[['R003', 'R005']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Correlations and Pearson R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pearson's R only measures LINEAR correlations!\n",
    "* Pandas std() function automatically uses Bessel's correction so you need to add (ddof = 0) so that it's NOT used.\n",
    "* this is just to show you what's going on. You should actually just use numpys corrcoef() function instead of doing this. It's easier.\n",
    "1. standardize each variable. This converts both variables to a similar scale.\n",
    "2. multiply each pair of values, and take the average\n",
    "r = average (x in standard units) * (y in standard units)\n",
    "Look at example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    std_x = (x - x.mean()) / x.std(ddof=0)\n",
    "    std_y = (y - y.mean()) / y.std(ddof=0)\n",
    "    \n",
    "    return r = (std_x * std_y).mean() # apparently doing the .mean takes the average IT\n",
    "\n",
    "# now you can plug in differnt columns and see if they're correlated. The closer you get to 1 the more linear correlcation their is\n",
    "# between those 2 columns. The closer to -1 the more negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
